{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert given array as a sparse connected fcn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/example1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/example2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection also represents its acitvation function\n",
    "- 0 : not connected\n",
    "- 1 : linear \n",
    "- 2 : ReLU\n",
    "- 3 : Sigmoid\n",
    "- and so on..\n",
    "\n",
    "**this can be changed**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- [Concatenate layer output with additional input data](https://discuss.pytorch.org/t/concatenate-layer-output-with-additional-input-data/20462)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# class MatrixForWANN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixForWANN() : \n",
    "    def __init__(self, mat, in_dim, out_dim) : \n",
    "        \n",
    "        # get when intiliazed\n",
    "        self.mat = mat\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        \n",
    "        # calculate\n",
    "        self.num_hidden_nodes = self.mat.shape[1]-self.in_dim\n",
    "        self.hidden_dim = self.get_hidden_dim()\n",
    "        \n",
    "    def get_hidden_dim(self):\n",
    "        in_dim = self.in_dim\n",
    "        out_dim = self.out_dim\n",
    "        mat_mask = self.mat\n",
    "        hidden_dim_list = []\n",
    "        start_col_idx = 0 \n",
    "        finish_col_idx = in_dim-1\n",
    "\n",
    "        while(True):\n",
    "\n",
    "            if finish_col_idx >= mat_mask.shape[1]:\n",
    "                break\n",
    "\n",
    "            for i in range(start_col_idx, len(mat_mask)): \n",
    "                if (mat_mask[i,start_col_idx:(finish_col_idx + 1)].sum() == 0):\n",
    "                    hidden_dim = i - sum(hidden_dim_list)\n",
    "                    hidden_dim_list += [hidden_dim] \n",
    "                    start_col_idx = finish_col_idx + 1\n",
    "                    finish_col_idx += i \n",
    "                    break\n",
    "        return hidden_dim_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.array([[0,2,0,0,2,0,0,0,0,0],\n",
    "                [2,0,2,0,0,0,0,0,0,0],\n",
    "                [0,2,0,2,0,0,0,0,0,0],\n",
    "                [0,0,0,0,0,1,1,0,0,0],\n",
    "                [0,0,0,0,0,0,1,1,0,0],\n",
    "                [0,0,0,0,0,0,0,0,0,3],\n",
    "                [0,0,0,0,0,0,0,0,3,0]])\n",
    "in_dim = 5\n",
    "out_dim = 2\n",
    "mat_wann = MatrixForWANN(mat, in_dim, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 0, 2, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first position represents row : FROM\n",
    "mat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# second position represents column : TO\n",
    "mat[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 0, 0, 2],\n",
       "       [2, 0, 2, 0, 0],\n",
       "       [0, 2, 0, 2, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get destinations of input layer\n",
    "mat[:mat_wann.num_hidden_nodes, :in_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of nodes for each hidden layer\n",
    "mat_wann.hidden_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# class WANNFCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_wann.num_hidden_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 0, 0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get hidden nodes which is connected from input layer\n",
    "# 1 : connected, 0 : not connected\n",
    "# positional index : node index for given hidden node\n",
    "def hiddens_from_input(mat, num_hidden_nodes, in_dim) : \n",
    "    hidden_nodes_connected_from_input = []\n",
    "    for i in range(num_hidden_nodes) : \n",
    "        hidden_nodes_connected_from_input.append(1 if mat[i, :in_dim].sum() != 0 else 0)\n",
    "    return hidden_nodes_connected_from_input\n",
    "hiddens_from_input(mat, mat_wann.num_hidden_nodes, in_dim)\n",
    "\n",
    "# hidden nodes 중에서, input이랑 연결된 애들의 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 0, 2])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get index of input node which is connected to the given hidden node\n",
    "idx_hidden_node = 0\n",
    "mat[idx_hidden_node, :in_dim]\n",
    "\n",
    "# 주어진 hiddden node에 대해서, 얘랑 연결되는 input node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1, 1]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def output_from_hiddens(mat, num_hidden_nodes, out_dim) : \n",
    "    output_nodes_connected_from_hidden = []\n",
    "    for i in range(mat.shape[0]-out_dim, mat.shape[1]) : \n",
    "        output_nodes_connected_from_hidden.append(1 if mat[-out_dim:, i].sum() != 0 else 0)\n",
    "    return output_nodes_connected_from_hidden\n",
    "output_from_hiddens(mat, mat_wann.num_hidden_nodes, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get index of hidden node which is connected to the given output node\n",
    "idx_output_node = 0\n",
    "mat[mat_wann.num_hidden_nodes+idx_output_node, in_dim:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activations = [None, None, self.relu, self.sigmoid]\n",
    "def wrap_activation(x, idx_activation, activations) : \n",
    "    if idx_activation == 1 :\n",
    "        return x\n",
    "    elif idx_activation == 2 :\n",
    "        return activations[2](x)\n",
    "    elif idx_activation == 3 :\n",
    "        return activations[3](x)\n",
    "    else : \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_wann.hidden_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_wann.num_hidden_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Linear(28, 1)[27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WANNFCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linear를 마지막ㅇ 넣으면 weight bias가 또 생길수 있음\n",
    "- Activation function 씌울때 Linear를 먼저 만들고, activation을 씌워야..\n",
    "- 그러니까 Linear를 정의할게 아니라 concat으로만 주는게 ...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n",
      "{'hidden_0': tensor([[0.2935],\n",
      "        [0.5902],\n",
      "        [0.8869]], grad_fn=<AddmmBackward>), 'hidden_1': tensor([[0.8985],\n",
      "        [2.2537],\n",
      "        [3.6088]], grad_fn=<AddmmBackward>), 'hidden_2': tensor([[-1.1512],\n",
      "        [-4.5000],\n",
      "        [-7.8488]], grad_fn=<AddmmBackward>)}\n",
      "{'hidden_0': tensor([[0.2935],\n",
      "        [0.5902],\n",
      "        [0.8869]], grad_fn=<AddmmBackward>), 'hidden_1': tensor([[0.8985],\n",
      "        [2.2537],\n",
      "        [3.6088]], grad_fn=<AddmmBackward>), 'hidden_2': tensor([[-1.1512],\n",
      "        [-4.5000],\n",
      "        [-7.8488]], grad_fn=<AddmmBackward>)}\n",
      "{'hidden_0': tensor([[0.2935],\n",
      "        [0.5902],\n",
      "        [0.8869]], grad_fn=<AddmmBackward>), 'hidden_1': tensor([[0.8985],\n",
      "        [2.2537],\n",
      "        [3.6088]], grad_fn=<AddmmBackward>), 'hidden_2': tensor([[-1.1512],\n",
      "        [-4.5000],\n",
      "        [-7.8488]], grad_fn=<AddmmBackward>)}\n"
     ]
    }
   ],
   "source": [
    "class WANNFCN(nn.Module) : \n",
    "    def __init__(self, mat_wann) : \n",
    "        super(WANNFCN, self).__init__()\n",
    "        self.mat = mat_wann.mat\n",
    "        self.in_dim = mat_wann.in_dim\n",
    "        self.out_dim = mat_wann.out_dim\n",
    "        self.num_hidden_nodes = mat_wann.num_hidden_nodes\n",
    "        self.hidden_dim = mat_wann.hidden_dim\n",
    "        \n",
    "        self.relu = nn.ReLU() # 2\n",
    "        self.sigmoid = nn.Sigmoid() # 3\n",
    "        self.activations = [None, None, self.relu, self.sigmoid]\n",
    "        \n",
    "    def forward(self, x) : # forward determines connections\n",
    "        nodes = {}\n",
    "        #node_counts = 0 # number of nodes connected \n",
    "        for idx_hidden_layer, num_hidden_nodes in enumerate(self.hidden_dim) :\n",
    "\n",
    "            # 1. First layer\n",
    "            if idx_hidden_layer == 0 :\n",
    "                # index of hidden nodes in first layer\n",
    "                indices_hidden = list(range(0, num_hidden_nodes))\n",
    "                print(indices_hidden)\n",
    "                # check connection for nodes in first layer\n",
    "                # idx_hidden : index of hidden node (0~last index of first layer)\n",
    "                # connection : 1-connected, 0-not\n",
    "                for idx_hidden, connection in enumerate(hiddens_from_input(self.mat, self.num_hidden_nodes, self.in_dim)[:num_hidden_nodes]) : \n",
    "                    if connection != 0 : # connected\n",
    "                        # array below contains info. about connection from input and its activation\n",
    "                        # e.g.) self.mat[idx_hidden, :self.in_dim] : array([0, 2, 0, 0, 2])\n",
    "                        # idx_input : index of input node\n",
    "                        # activation_type : 0-not connected, 1,2,3..-connected with given activation function\n",
    "                        count_connection = 0 \n",
    "                        input_node = None\n",
    "                        for idx_input, activation_type in enumerate(self.mat[idx_hidden, :self.in_dim]) :\n",
    "                            # connected first input node\n",
    "                            if activation_type != 0 and count_connection == 0  :\n",
    "                                # x[idx_for_batch, idx_for_position]\n",
    "                                input_node = wrap_activation(x[:, idx_input], activation_type, self.activations).reshape(-1, 1)\n",
    "                                count_connection += 1\n",
    "                            # connected other input node\n",
    "                            elif activation_type != 0 and count_connection != 0 : \n",
    "                                input_node = torch.cat([input_node,\n",
    "                                                       wrap_activation(x[:, idx_input], activation_type, self.activations).reshape(-1, 1)\n",
    "                                                       ], dim=1)\n",
    "                                count_connection += 1\n",
    "\n",
    "                        # connect corresponding input node to nodes['hidden_(node number)']\n",
    "                        input_node = input_node.view(-1, count_connection)\n",
    "                        nodes['hidden_%d'%idx_hidden] = nn.Linear(count_connection, 1)(input_node)\n",
    "                \n",
    "                #node_counts += num_hidden_nodes\n",
    "            print(nodes)\n",
    "            # 2. Hidden Layers\n",
    "            \n",
    "            '''\n",
    "            난 내일 이 코드를 다시 열어봤을때 내 코드를 이해하거나 리팩토링할 자신이 없다\n",
    "            흑흑....\n",
    "            '''\n",
    "\n",
    "            '''\n",
    "            # 3. Last Layer\n",
    "            if idx_hidden_layer == len(self.hidden_dim)-1 : \n",
    "                \n",
    "                indices_output = list(range(0, self.out_dim)) # in row\n",
    "                indices_output = [x+self.num_hidden_nodes for x in indices_output]\n",
    "                print('indices_output', indices_output)\n",
    "                \n",
    "                for idx_output in indices_output : # output node에 대해 도는 loop\n",
    "                    print('outputidx(row) : %s, output:%s' %(idx_output, self.mat[idx_output, self.in_dim:]))\n",
    "                    count_connection = 0\n",
    "                    hidden_node = None\n",
    "                    \n",
    "                    for idx_hidden, connection in enumerate(self.mat[idx_output, self.in_dim:]) : # hidden node에 대해 도는 loop\n",
    "                        print('hidden idx(column) : %s, connection : %s' %(idx_hidden+self.in_dim, connection))\n",
    "                        \n",
    "                        if connection != 0 : # connected\n",
    "                            print('activation_type %s count_connection %s connection %s' % (activation_type, count_connection, connection))\n",
    "                            if connection != 0 and count_connection == 0 :\n",
    "                                print('case 1 start')\n",
    "                                hidden_node = wrap_activation(nodes['hidden_%d'%(idx_hidden)], activation_type, self.activations).reshape(-1, 1)\n",
    "                                count_connection += 1\n",
    "                                print('case 1 end')\n",
    "                            elif connection != 0 and count_connection != 0 :\n",
    "                                print('case 2 start')\n",
    "                                hidden_node = torch.cat([hidden_node, wrap_activation(nodes['hidden_%d'%(idx_hidden)], \n",
    "                                                                                      activation_type,\n",
    "                                                                                      self.activations).reshape(-1, 1)], dim=1)\n",
    "                                count_connection += 1\n",
    "                                print('case 2 end')\n",
    "                    hidden_node = hidden_node.view(-1, count_connection)\n",
    "                    nodes['output_%d'%(idx_output-self.num_hidden_nodes)] = nn.Linear(count_connection, 1)(hidden_node)\n",
    "            '''\n",
    "            \n",
    "    \n",
    "                    \n",
    "                \n",
    "               \n",
    "                \n",
    "\n",
    "        print(nodes)\n",
    "        '''\n",
    "        nodes라는 dictionary 안에 아래와 같이 저장됨\n",
    "        'hidden_1' : 해당 노드\n",
    "        'hidden_2' : 해당 노드\n",
    "        ...\n",
    "        'output_1' : 해당 output 노드\n",
    "        'output_2' : 해당 output 노드\n",
    "        '''\n",
    "        output_1 = activation(hidden_5*weight + bias) + activaiton(hidden_6*weight + bias)\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "model = WANNFCN(mat_wann)\n",
    "\n",
    "numpy_input = np.array([[1,2,3,4,5],\n",
    "                        [6,7,8,9,10],\n",
    "                        [11,12,13,14,15]])\n",
    "numpy_input = torch.from_numpy(numpy_input).float()\n",
    "\n",
    "model(numpy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    def forward(self, x) : # forward determines connections\n",
    "        # \n",
    "        nodes={}   \n",
    "        # 1. get indices of first nodes connected to first hidden layer\n",
    "        # e.g.) hiddens_from_input : [1, 1, 1, 0, 0], 1: connected, 0: not connected\n",
    "        # idx_hidden : index of hidden node\n",
    "        # connection : 1-connected, 0-not\n",
    "        for idx_hidden, connection  in enumerate(hiddens_from_input(self.mat, self.in_dim)) :\n",
    "            if connection != 0 : # connected\n",
    "                # array below contains info. about connection from input and its activation\n",
    "                # e.g.) self.mat[idx_hidden, :self.in_dim] : array([0, 2, 0, 0, 2])\n",
    "                # idx_input : index of input node\n",
    "                # activation_type : 0-not connected, 1,2,3..-connected with given activation function\n",
    "                print(self.mat[idx_hidden, :self.in_dim])\n",
    "                count_connection = 0 \n",
    "                input_node = None\n",
    "                for idx_input, activation_type in enumerate(self.mat[idx_hidden, :self.in_dim]) :\n",
    "                    # for debugging\n",
    "                    print(idx_input, count_connection, activation_type, input_node)\n",
    "                    # connected first input node\n",
    "                    if activation_type != 0 and count_connection == 0  :\n",
    "                        # x[idx_for_batch, idx_for_position]\n",
    "                        input_node = wrap_activation(x[:, idx_input], activation_type, self.activations).reshape(-1, 1)\n",
    "                        count_connection += 1\n",
    "                    # connected other input node\n",
    "                    elif activation_type != 0 and count_connection != 0 : \n",
    "                        input_node = torch.cat([input_node,\n",
    "                                               wrap_activation(x[:, idx_input], activation_type, self.activations).reshape(-1, 1)\n",
    "                                               ], dim=1)\n",
    "                        count_connection += 1\n",
    "                    \n",
    "                # connect corresponding input node to nodes['hidden_(node number)']\n",
    "                input_node = input_node.view(-1, count_connection)\n",
    "                print(input_node, nn.Linear(count_connection, 1), count_connection)\n",
    "                nodes['hidden_%d'%idx_hidden] = nn.Linear(count_connection, 1)(input_node)\n",
    "\n",
    "\n",
    "        return nodes\n",
    "''''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
