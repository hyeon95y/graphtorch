{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Given array as a sparse connected fcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0: not connected\n",
    "# 1: linear\n",
    "# 2: ReLU\n",
    "# 3: sigmoid\n",
    "\n",
    "activations = [None, None, nn.ReLU(), nn.Sigmoid()]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixForWANN():\n",
    "    \n",
    "    def __init__(self, mat, in_dim, out_dim):\n",
    "        # get when initialized\n",
    "        self.mat = mat  \n",
    "        self.in_dim = in_dim  \n",
    "        self.out_dim = out_dim  \n",
    "        \n",
    "        #calculate\n",
    "        self.num_hidden_nodes = self.mat.shape[1] - self.in_dim   \n",
    "        \n",
    "        #when matrix has hidden layer  \n",
    "        if self.num_hidden_nodes == 1:  \n",
    "            self.hidden_dim = [1] \n",
    "        elif self.num_hidden_nodes == 0:\n",
    "            self.hidden_dim = []\n",
    "        else:\n",
    "            self.hidden_dim = self.get_hidden_dim()   \n",
    "            \n",
    "            \n",
    "    def get_hidden_dim(self):\n",
    "        in_dim = self.in_dim\n",
    "        out_dim = self.out_dim\n",
    "        mat_mask = self.mat\n",
    "        \n",
    "        hidden_dim_list = []\n",
    "        start_col_idx = 0\n",
    "        finish_col_idx = in_dim -1   \n",
    "        \n",
    "        while(True):\n",
    "            \n",
    "            if finish_col_idx >= mat_mask.shape[1]:   \n",
    "                print(finish_col_idx)\n",
    "                break  \n",
    "            \n",
    "            if ((mat_mask.shape[0] - sum(hidden_dim_list)) == out_dim):  #example4 해결\n",
    "                 break  #지금 hidden dimension들 합이랑 output dim 합이 row길이랑 같으면 더이상 탐색 필요 x\n",
    "            \n",
    "            for i in range(sum(hidden_dim_list), len(mat_mask)): #이부분이상한데..?   \n",
    "    \n",
    "                #밑에처럼 하면 example 2에서 오류가 남.\n",
    "                #skip connection에 대한 예외처리 해줘야 함   \n",
    "    \n",
    "                if(mat_mask[i,start_col_idx:(finish_col_idx + 1)].sum() == 0):   \n",
    "                \n",
    "                    hidden_dim = i - sum(hidden_dim_list)\n",
    "                    hidden_dim_list += [hidden_dim]\n",
    "                    start_col_idx = finish_col_idx + 1\n",
    "                    finish_col_idx += hidden_dim   \n",
    "                    break    \n",
    "                    \n",
    "        return hidden_dim_list     \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat4 = np.array([[3,0,1,0,0],   \n",
    "                [0,3,0,0,0],     \n",
    "                [0,0,0,2,0],  \n",
    "                [0,0,0,0,2],   \n",
    "                [0,0,1,2,0],   \n",
    "                [0,0,1,0,0]])    \n",
    "in_dim = 3   \n",
    "out_dim = 4  \n",
    "mat_wann4 = MatrixForWANN(mat4, in_dim, out_dim)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_wann4.hidden_dim   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat5 = np.array([[0,2,0,0,2,0,0,0,0,0],  \n",
    "                [2,0,2,0,0,0,0,0,0,0],  \n",
    "                [0,2,0,2,0,0,0,0,0,0],  \n",
    "                [0,0,0,0,0,1,1,0,0,0],\n",
    "                [0,0,0,2,0,0,1,1,0,0], \n",
    "                [0,0,0,0,0,0,0,0,0,3],\n",
    "                [0,0,0,0,0,0,0,0,3,0]])   \n",
    "in_dim = 5   \n",
    "out_dim = 2   \n",
    "mat_wann5 = MatrixForWANN(mat5, in_dim, out_dim)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_wann5.hidden_dim   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat3 = np.array([[2,0,0,3,0],\n",
    "                [0,0,0,0,1]])  \n",
    "in_dim = 5  \n",
    "out_dim = 2  \n",
    "mat_wann3 = MatrixForWANN(mat3, in_dim, out_dim)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_wann3.hidden_dim  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat2 = np.array([[2,0,0,0,0,0],\n",
    "                [0,0,0,3,0,1]])\n",
    "in_dim = 5\n",
    "out_dim = 1\n",
    "mat_wann2 = MatrixForWANN(mat2, in_dim, out_dim)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_wann2.hidden_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat1 = np.array([[0,2,0,0,2,0,0,0,0,0],\n",
    "                [2,0,2,0,0,0,0,0,0,0],\n",
    "                [0,2,0,2,0,0,0,0,0,0],\n",
    "                [0,0,0,0,0,1,1,0,0,0],\n",
    "                [0,0,0,0,0,0,1,1,0,0],\n",
    "                [0,0,0,0,0,0,0,0,0,3],  \n",
    "                [0,0,0,0,0,0,0,0,3,0]])\n",
    "in_dim = 5\n",
    "out_dim = 2\n",
    "mat_wann1 = MatrixForWANN(mat1, in_dim, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_wann1.hidden_dim  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class WANNFCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_activation(x, idx_activation, activations):   \n",
    "    if idx_activation == 0:\n",
    "        assert True\n",
    "    elif idx_activation == 1:\n",
    "        return nn.Linear(1,1)(x)\n",
    "    else:\n",
    "        return activations[idx_activation](nn.Linear(1,1)(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WANNFCN(nn.Module):\n",
    "    \n",
    "    def __init__(self, mat_wann, activations):  \n",
    "        super(WANNFCN, self).__init__()\n",
    "        self.mat = mat_wann.mat\n",
    "        self.in_dim = mat_wann.in_dim\n",
    "        self.out_dim = mat_wann.out_dim  \n",
    "        self.num_hidden_nodes = mat_wann.num_hidden_nodes\n",
    "        self.hidden_dim = mat_wann.hidden_dim\n",
    "        \n",
    "        self.activations = activations\n",
    "        \n",
    "        self.nodes = {} #node 담는 딕셔너리\n",
    "    \n",
    "    \n",
    "    def to_hidden(self, x):\n",
    "        \n",
    "        hidden_node_counts = 0\n",
    "        \n",
    "        for idx_hidden_layer, num_hidden_nodes in enumerate(self.hidden_dim): #각 hidden layer와 그에 해당하는 dimension\n",
    "            \n",
    "            #First hidden layer\n",
    "            if idx_hidden_layer == 0:\n",
    "                indices_hidden_row = list(range(0, num_hidden_nodes))\n",
    "                for idx_hidden_row in indices_hidden_row: #각 hidden layer마다 hidden node list \n",
    "                    connections_from_input = self.mat[idx_hidden_row, :self.in_dim] #matrix 잘라옴 (한 hidden node에 대해서)\n",
    "                    if connections_from_input.sum() != 0:  \n",
    "                        count_connection = 0\n",
    "                        input_node = None  \n",
    "                        \n",
    "                        for idx_input_col, activation_type in enumerate(connections_from_input):\n",
    "                            if activation_type != 0 and count_connection == 0:\n",
    "                                input_node = wrap_activation(x[:, idx_input_col].view(-1,1), activation_type, activations)  \n",
    "                                count_connection += 1\n",
    "                            elif activation_type !=0 and count_connection != 0:\n",
    "                                new_node = wrap_activation(x[:, idx_input_col].view(-1,1), activation_type, activations)\n",
    "            \n",
    "                    self.nodes['hidden_%d'%idx_hidden_row] = input_node     \n",
    "            \n",
    "            else: # other hidden layers\n",
    "                indices_hidden_row = list()\n",
    "                \n",
    "                \n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
